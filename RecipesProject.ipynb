{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains code to find recipes that are similar to other recipes in our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the recipes database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RD = pd.read_pickle('./Recipes_DataFrame.pkl')\n",
    "# Look at the database\n",
    "RD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert ingredients and instructions to lower case\n",
    "RD['Ingredients and Instructions'] = RD['Ingredients and Instructions'].\\\n",
    "                                        apply(lambda row: row.lower())\n",
    "RD.head()\n",
    "\n",
    "import string\n",
    "# remove punctuations using the character deletion step of translate\n",
    "RD['Ingredients and Instructions'] = RD['Ingredients and Instructions'].\\\n",
    "apply(lambda row: row.translate(None, string.punctuation))\n",
    "RD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tf-idf (term frequency - inverse document frequency)\n",
    "Tf-idf reflects how important a word (ingredient or instruction) is in a recipe compared to all other recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import some modules for calculating tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a function that will tokenize and stem words\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = []\n",
    "    for token in tokens:\n",
    "        stems.append(stemmer.stem(token))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "\n",
    "# Obtain a matrix with tf-idfs for different recipes. \n",
    "# The columns of the matrix will contain features, \n",
    "# which are the weighted frequency of tokens\n",
    "tfidf_mat = tfidf.fit_transform(RD['Ingredients and Instructions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows that are entirely zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# remove rows that are entirely zero from the tfidf matrix and also from recipes names\n",
    "num_nonzeros =  np.diff(tfidf_mat.indptr)\n",
    "zeros_ind = np.nonzero(num_nonzeros == 0)[0][0]\n",
    "tfidf_mat =  tfidf_mat[num_nonzeros != 0]\n",
    "\n",
    "#Also remove those recipes from the recipes databse\n",
    "RD = RD.drop(RD.index[zeros_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the cosine similarity between recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import module to calculate distances between vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similarity[i,j] will store how far recipe i is from recipe j\n",
    "similarity = cosine_similarity(tfidf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a couple of examples of similar recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_lime_bars = RD[RD['Name'] == 'Key Lime Bars'].index[0]\n",
    "key_lime_cookies = RD[RD['Name'] == 'Key Lime Cookies'].index[0]\n",
    "brussels_sprouts = RD[RD['Name'] == 'Buffalo Brussels Sprouts'].index[0]\n",
    "\n",
    "# for sanity check, make sure that a recipe is 100% similar to itself\n",
    "print \"Similarity between key lime bars and itself = \", \\\n",
    "similarity[key_lime_bars, key_lime_bars]\n",
    "print \"Similarity between key lime cookies and itself = \", \\\n",
    "similarity[key_lime_cookies, key_lime_cookies]\n",
    "print \"Similarity between buffalo brussels sprouts and itself = \", \\\n",
    "similarity[brussels_sprouts, brussels_sprouts]\n",
    "\n",
    "# also check how similar these are to one another\n",
    "print \"Similarity between key lime bars and key lime cookies = \", \\\n",
    "similarity[key_lime_bars, key_lime_cookies]\n",
    "print \"Similarity between key lime bars and buffalo brussels sprouts = \", \\\n",
    "similarity[key_lime_bars, brussels_sprouts]\n",
    "print \"Similarity between key lime cookies and buffalo brussels sprouts = \", \\\n",
    "similarity[key_lime_cookies, brussels_sprouts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now find the five most similar recipes to given recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import nearest neighbors module\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "num_interest = 3\n",
    "# initialize the model\n",
    "neigh = NearestNeighbors(n_neighbors = num_interest, algorithm='auto')\n",
    "# fit the model\n",
    "neigh.fit(tfidf_mat)\n",
    "nearest_neighbors = neigh.kneighbors(return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_names = ['Bacon Cheese Puff Balls', 'Mexican Flan', \\\n",
    "               'Spicy Buffalo Wings', 'Key Lime Bars', \\\n",
    "              'Key Lime Cookies', 'Cranberry Margarita']\n",
    "closest_recipes = []\n",
    "for recipe in query_names:\n",
    "    query_ind = RD[RD['Name'] == recipe].index[0]\n",
    "    curr_recipe_close_recipes = []\n",
    "    for i in xrange(num_interest):\n",
    "        curr_ind = nearest_neighbors[query_ind,i]\n",
    "        curr_recipe_close_recipes.append(RD['Name'][curr_ind])\n",
    "    \n",
    "    closest_recipes.append(curr_recipe_close_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display this data in a table\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.axis('off')\n",
    "colLabels =xrange(1,num_interest+1)\n",
    "table = ax.table(cellText=closest_recipes, rowLabels=query_names,\\\n",
    "            colLabels=colLabels, loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(200)\n",
    "table.scale(50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website \"Gourmetsleuth.com\" has categorized these recipes into 9 different courses. The dataframe we created stores these categories in the column 'Classification'. Let's see if we can implement a learning algorithm to classify these recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RD.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the first few entries\n",
    "RD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The array below lists the categories\n",
    "categories = ['Appetizers and Snacks', 'Bread, Muffins and Rolls', 'Breakfast and Brunch', \n",
    "                'Desserts', 'Drinks and Beverages', 'Main Dishes', 'Salads and Dressings',\n",
    "             'Sides', 'Soups, Stews and Chili']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualize the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tfidf_mat\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X = pca.fit_transform(X.toarray())\n",
    "Y = RD['Classification'].values\n",
    "fig = plt.figure(1, figsize=(10, 4))\n",
    "plt.clf()\n",
    "plt.scatter(X[:,0], X[:,1], c=Y, cmap=plt.cm.spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tfidf_mat\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "X = pca.fit_transform(X.toarray())\n",
    "Y = RD['Classification'].values\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(1, figsize=(10, 4))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=15, azim=210)\n",
    "scatplot = ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=Y, cmap=plt.cm.spectral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tfidf_mat\n",
    "Y = RD['Classification'].values\n",
    "# first shuffle the entries\n",
    "num_recipes = X.shape[0]\n",
    "ind = np.random.permutation(num_recipes)\n",
    "\n",
    "# separate into training and test set\n",
    "train_num = int(round(.9*num_recipes))\n",
    "train_ind = ind[:train_num]\n",
    "test_ind = ind[train_num:]\n",
    "\n",
    "train_X = X[train_ind,:]\n",
    "train_Y = Y[train_ind]\n",
    "\n",
    "test_X = X[test_ind,:]\n",
    "test_Y = Y[test_ind]\n",
    "\n",
    "print \"num_train_data = \", len(train_Y)\n",
    "print \"num_test_data = \", len(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# create a logistic regression classifier that uses a cross-validation set to\n",
    "# find the optimum C parameter\n",
    "logreg = linear_model.LogisticRegressionCV(solver='liblinear', penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the training data\n",
    "logreg.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the classification on the test data\n",
    "expected = test_Y\n",
    "predicted = logreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "     % (logreg, metrics.classification_report(expected, predicted)))\n",
    "print (\"The classification categories are as follows:\")\n",
    "num_categories = len(categories)\n",
    "for i in xrange(num_categories):\n",
    "    print (\"%d %s\" % (i, categories[i]))\n",
    "print(\"\\nConfusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# project the result to 2D\n",
    "diff_results = 20*np.ones(test_Y.shape)\n",
    "diff_results[expected != predicted] = 0\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "test_X_2d = pca.fit_transform(test_X.toarray())\n",
    "fig = plt.figure(1, figsize=(10, 4))\n",
    "plt.clf()\n",
    "correct = plt.scatter(test_X_2d[expected==predicted,0], test_X_2d[expected==predicted,1], c='white')\n",
    "incorrect = plt.scatter(test_X_2d[expected!=predicted,0], test_X_2d[expected!=predicted,1],\n",
    "                        marker='x', c='red')\n",
    "plt.legend((correct, incorrect), ('correctly classified', 'incorrectly classified'),\n",
    "           loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
